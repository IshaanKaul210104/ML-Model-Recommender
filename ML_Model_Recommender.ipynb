{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4ZgYpX0mFh//38G5MbIqC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IshaanKaul210104/ML-Model-Recommender/blob/main/ML_Model_Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 1: Import Libraries**"
      ],
      "metadata": {
        "id": "D_6fMyK0MVPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Imports -----------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing, load_diabetes, make_friedman1\n",
        "from sklearn.datasets import load_iris, load_wine, make_classification, make_blobs\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score, silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.exceptions import NotFittedError\n",
        "from scipy.stats import skew\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "6S71NkfeMWQh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 2: Meta-Feature Calculator**"
      ],
      "metadata": {
        "id": "ZO9XbFv2MYs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Meta-Feature Calculation -----------------------\n",
        "def calculate_meta_features(X, y=None, task='regression'):\n",
        "    meta = {}\n",
        "    meta['avg_skewness'] = np.mean(np.abs(skew(X)))\n",
        "\n",
        "    if task in ['regression', 'classification'] and y is not None:\n",
        "        correlations = []\n",
        "        for col in X.columns:\n",
        "            try:\n",
        "                correlations.append(np.corrcoef(X[col], y)[0, 1])\n",
        "            except:\n",
        "                correlations.append(0)\n",
        "        meta['avg_correlation_with_target'] = np.nanmean(np.abs(correlations))\n",
        "    else:\n",
        "        meta['avg_correlation_with_target'] = 0\n",
        "\n",
        "    vif_matrix = np.linalg.pinv(np.corrcoef(X.T))  # pseudo-inverse to avoid errors\n",
        "    meta['multicollinearity_score'] = np.trace(vif_matrix)\n",
        "\n",
        "    return meta"
      ],
      "metadata": {
        "id": "Tqka1_6_McFv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 3: Model Recommender**"
      ],
      "metadata": {
        "id": "b8Re2xMiQbHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Model Recommender -----------------------\n",
        "def recommend_model(meta, task='regression'):\n",
        "    if task == 'regression':\n",
        "        if meta['avg_skewness'] > 2 or meta['multicollinearity_score'] > 50:\n",
        "            return RandomForestRegressor()\n",
        "        elif meta['avg_correlation_with_target'] > 0.5:\n",
        "            return Ridge()\n",
        "        else:\n",
        "            return LinearRegression()\n",
        "\n",
        "    elif task == 'classification':\n",
        "        if meta['multicollinearity_score'] > 50:\n",
        "            return RandomForestClassifier()\n",
        "        elif meta['avg_correlation_with_target'] > 0.4:\n",
        "            return LogisticRegression()\n",
        "        else:\n",
        "            return RandomForestClassifier()\n",
        "\n",
        "    elif task == 'clustering':\n",
        "        if meta['avg_skewness'] > 2:\n",
        "            return DBSCAN()\n",
        "        else:\n",
        "            return KMeans(n_clusters=3, random_state=42)"
      ],
      "metadata": {
        "id": "UZoPyos9Qev4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 4: Model Trainer and Evaluator**"
      ],
      "metadata": {
        "id": "YG4CqrwRQmiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Training & Evaluation -----------------------\n",
        "def train_and_evaluate(model, X, y=None, task='regression'):\n",
        "    if task == 'regression':\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        print(\"\\nðŸ“Š Model Evaluation:\")\n",
        "        print(\"RÂ² Score:\", r2_score(y_test, y_pred))\n",
        "        print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
        "\n",
        "    elif task == 'classification':\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        print(\"\\nðŸ“Š Model Evaluation:\")\n",
        "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "    elif task == 'clustering':\n",
        "        model.fit(X)\n",
        "        labels = model.labels_ if hasattr(model, 'labels_') else model.predict(X)\n",
        "        score = silhouette_score(X, labels)\n",
        "        print(\"\\nðŸ“Š Clustering Evaluation:\")\n",
        "        print(\"Silhouette Score:\", score)"
      ],
      "metadata": {
        "id": "tBxMsJhcQpOD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 5: Dataset Loader**"
      ],
      "metadata": {
        "id": "wRRXsoIVQrUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Built-in Dataset Loader -----------------------\n",
        "def load_builtin_dataset(task_type):\n",
        "    if task_type == \"regression\":\n",
        "        print(\"Available datasets: 1. California Housing  2. Diabetes  3. Friedman1\")\n",
        "        choice = input(\"Select (1/2/3): \")\n",
        "        if choice == \"1\":\n",
        "            data = fetch_california_housing(as_frame=True).frame\n",
        "        elif choice == \"2\":\n",
        "            data = load_diabetes(as_frame=True).frame\n",
        "        elif choice == \"3\":\n",
        "            X, y = make_friedman1(n_samples=1000, n_features=10, noise=1.0, random_state=42)\n",
        "            data = pd.DataFrame(X, columns=[f\"X{i}\" for i in range(X.shape[1])])\n",
        "            data['target'] = y\n",
        "        else:\n",
        "            raise ValueError(\"Invalid selection.\")\n",
        "\n",
        "    elif task_type == \"classification\":\n",
        "        print(\"Available datasets: 1. Iris  2. Wine  3. Make Classification\")\n",
        "        choice = input(\"Select (1/2/3): \")\n",
        "        if choice == \"1\":\n",
        "            data = load_iris(as_frame=True).frame\n",
        "        elif choice == \"2\":\n",
        "            data = load_wine(as_frame=True).frame\n",
        "        elif choice == \"3\":\n",
        "            X, y = make_classification(n_samples=1000, n_features=10, n_classes=3, random_state=42)\n",
        "            data = pd.DataFrame(X, columns=[f\"X{i}\" for i in range(X.shape[1])])\n",
        "            data['target'] = y\n",
        "        else:\n",
        "            raise ValueError(\"Invalid selection.\")\n",
        "\n",
        "    elif task_type == \"clustering\":\n",
        "        print(\"Available datasets: 1. Blobs\")\n",
        "        choice = input(\"Select (1): \")\n",
        "        if choice == \"1\":\n",
        "            X, _ = make_blobs(n_samples=500, n_features=5, centers=3, random_state=42)\n",
        "            data = pd.DataFrame(X, columns=[f\"X{i}\" for i in range(X.shape[1])])\n",
        "        else:\n",
        "            raise ValueError(\"Invalid selection.\")\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "PiOkOCNoQxTT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 6: Optional File Upload for Google Colab**"
      ],
      "metadata": {
        "id": "KUhtdISuQ3Mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Upload Dataset (Optional) -----------------------\n",
        "def upload_dataset():\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    for fname in uploaded.keys():\n",
        "        if fname.endswith('.csv'):\n",
        "            return pd.read_csv(fname)\n",
        "        elif fname.endswith('.xlsx'):\n",
        "            return pd.read_excel(fname)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported file format.\")"
      ],
      "metadata": {
        "id": "DNMpJt49Q4Dc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 7: Main Pipeline**"
      ],
      "metadata": {
        "id": "ecaa7_hcREA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Main Execution -----------------------\n",
        "task_type = input(\"What type of task? (regression/classification/clustering): \").strip().lower()\n",
        "\n",
        "print(\"\\nChoose dataset type:\\n1. Use built-in dataset\\n2. Upload your own dataset\")\n",
        "dataset_choice = input(\"Enter 1 or 2: \").strip()\n",
        "\n",
        "if dataset_choice == \"1\":\n",
        "    data = load_builtin_dataset(task_type)\n",
        "elif dataset_choice == \"2\":\n",
        "    data = upload_dataset()\n",
        "else:\n",
        "    raise ValueError(\"Invalid dataset choice.\")\n",
        "\n",
        "print(f\"\\nDataset loaded with shape: {data.shape}\\n\")\n",
        "print(\"Columns:\", list(data.columns))\n",
        "\n",
        "if task_type in ['regression', 'classification']:\n",
        "    target_col = input(\"Enter the name of the target column: \").strip()\n",
        "    y = data[target_col]\n",
        "    X = data.drop(columns=[target_col])\n",
        "else:\n",
        "    X = data\n",
        "    y = None\n",
        "\n",
        "# Keep only numerical columns and drop missing values\n",
        "X = X.select_dtypes(include=[np.number]).dropna()\n",
        "if y is not None:\n",
        "    y = y.loc[X.index]\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Calculate meta-features\n",
        "meta_features = calculate_meta_features(X_scaled, y, task=task_type)\n",
        "print(\"Avg skewness:\", meta_features['avg_skewness'])\n",
        "print(\"Avg correlation with target:\", meta_features['avg_correlation_with_target'])\n",
        "print(\"Multicollinearity score:\", meta_features['multicollinearity_score'])\n",
        "\n",
        "# Recommend and evaluate model\n",
        "model = recommend_model(meta_features, task=task_type)\n",
        "print(\"\\nâœ… Recommended model:\", model.__class__.__name__)\n",
        "train_and_evaluate(model, X_scaled, y, task=task_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATSili0tRE_F",
        "outputId": "3b5a999b-49db-47ff-87d9-b57a66367795"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What type of task? (regression/classification/clustering): regression\n",
            "\n",
            "Choose dataset type:\n",
            "1. Use built-in dataset\n",
            "2. Upload your own dataset\n",
            "Enter 1 or 2: 1\n",
            "Available datasets: 1. California Housing  2. Diabetes  3. Friedman1\n",
            "Select (1/2/3): 2\n",
            "\n",
            "Dataset loaded with shape: (442, 11)\n",
            "\n",
            "Columns: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'target']\n",
            "Enter the name of the target column: target\n",
            "Avg skewness: 0.408265651725193\n",
            "Avg correlation with target: 0.34185669222980936\n",
            "Multicollinearity score: 139.7138548950911\n",
            "\n",
            "âœ… Recommended model: RandomForestRegressor\n",
            "\n",
            "ðŸ“Š Model Evaluation:\n",
            "RÂ² Score: 0.4265944023756\n",
            "Mean Squared Error: 3037.9898696629216\n"
          ]
        }
      ]
    }
  ]
}